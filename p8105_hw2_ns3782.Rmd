---
title: "p8105_hw2_ns3782"
author: "NSK"
date: "2024-09-26"
output: github_document
toc: true
code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, include=FALSE}
library(tidyverse)
library(readxl)

```

# Problem 1

```{r problem_1}

## Read and clean NYC transit data

nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = case_match(
    entry,
    "YES" ~ TRUE,
    "NO" ~ FALSE,
    .default = NA
  ))

```

## Dataset overview

The cleaned NYC Transit Subway Entrance and Exit dataset contains information about entrances and exits of subway stations in New York City. Variables selected for inclusion in the cleaned dataset imported into R include the line, station name, location coordinates (latitude and longitude), routes served (route 1 through to route 11), entry, vending presence, entrance type, and ADA compliance. 

The data cleaning process involved reading the CSV file from a local subdirectory /data, cleaning variable names using the janitor package, selecting variables of interest, and converting the 'entry' variable from character ("YES"/"NO") to logical (TRUE/FALSE). 

The resulting dataset has **`r nrow(nyc_transit_df)` rows** and **`r ncol(nyc_transit_df)` columns**. The dataset is not tidy because information about routes served is spread across multiple columns (Route1 through Route11). This does not align with good tidy data practice, as each variable should form a column and each observation should form a row.

## How many distinct stations are there?

```{r distinct_stations}

nyc_transit_df %>%
  distinct(station_name, line) %>%
  nrow()

```

There are `r nyc_transit_df %>% distinct(station_name, line) %>% nrow()` distinct subway stations in the NYC transit subway system.


## How many stations are ADA compliant?

```{r ada}

nyc_transit_df %>%
  filter(ada == TRUE) %>%
  distinct(station_name, line) %>%
  nrow()


```

There are `r nyc_transit_df %>% filter(ada == TRUE) %>% distinct(station_name, line) %>% nrow()` ADA compliant stations.


## What proportion of station entrances / exits without vending allow entrance?

```{r allow_entry}

prop_no_vending_entry <- nyc_transit_df %>%
  filter(vending == "NO") %>%
  summarise(prop = mean(entry, na.rm = TRUE)) %>%
  pull(prop)

```

The proportion of station entrances/exits without vending that allow entrance is `r prop_no_vending_entry`, or `r scales::percent(prop_no_vending_entry, accuracy = 0.1)`.


# Problem 2

```{r problem_2}

## Read and clean Mr. Trash Wheel sheet

mr_trash_wheel_df <- read_excel(
  "./data/trash_wheel_collection_data.xlsx",
  sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N"),
  skip = 1
) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    trash_wheel = "Mr. Trash Wheel",
    year = as.numeric(year)
  )

## Read and clean Professor Trash Wheel sheet
prof_trash_wheel_df <- read_excel(
  "./data/trash_wheel_collection_data.xlsx",
  sheet = "Professor Trash Wheel",
  range = cell_cols("A:M"),
  skip = 1
) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    trash_wheel = "Professor Trash Wheel",
    year = as.numeric(year)
  )

## Read and clean Gwynnda Wheel sheet

gwynnda_trash_wheel_df <- read_excel(
  "./data/trash_wheel_collection_data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = cell_cols("A:L"),
  skip = 1
) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    trash_wheel = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )


## Combine all trash wheel datasets
combined_trash_wheel <- bind_rows(
  mr_trash_wheel_df, 
  prof_trash_wheel_df, 
  gwynnda_trash_wheel_df
) %>%
  select(trash_wheel, everything())

# Total weight collected by Prof Trash Wheel
prof_total_weight <- prof_trash_wheel_df %>%
  summarize(total_weight = sum(weight_tons)) %>%
  pull(total_weight)

# Total cigarette butts collected by Gwynnda June 2022
gwynnda_june_2022_butts <- gwynnda_trash_wheel_df %>%
  filter(month == "June", year == 2022) %>%
  summarize(total_butts = sum(cigarette_butts)) %>%
  pull(total_butts)

```

## Combined trash wheel Dataset Overview

The combined Trash Wheel dataset contains `r nrow(combined_trash_wheel)` observations and `r ncol(combined_trash_wheel)` variables. Key variables include the identifier for each trash wheel (`r unique(combined_trash_wheel$trash_wheel)`), the date of collection, the amount of trash collected (in tons and cubic yards), types of litter collected (e.g., plastic bottles, polystyrene, cigarette butts), and number of homes powered based on trash collected.

The data shows that Professor Trash Wheel has collected a total of `r prof_total_weight` tons of trash since its deployment. In June 2022, Gwynnda Trash Wheel collected `r scales::comma(gwynnda_june_2022_butts, accuracy = 1)` cigarette butts.

# Problem 3

## Importing and Cleaning datasets.

```{r p3_import_clean}

# Import and clean results csv

results_df <- read_csv("./data/results.csv", skip = 2) %>% 
  janitor::clean_names() %>%
  rename(baker_first_name = baker)

# Import and clean results bakers csv

bakers_df <- read_csv("./data/bakers.csv") %>% 
  janitor::clean_names() %>%
  separate(baker_name, into = c("baker_first_name", "baker_last_name"), sep = " ", extra = "merge")

# Import and clean results bakes csv

bakes_df <- read_csv("./data/bakes.csv") %>% 
  janitor::clean_names() %>%
  rename(baker_first_name = baker) %>%
  mutate(across(where(is.character), ~case_match(
    .,
    c("Unknown", "UNKNOWN", "N/A") ~ NA_character_,
    .default = . %>%
      str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
      str_replace_all("(?<=[a-z])with", " with") %>%
      str_replace_all("\\s+", " ") %>%
      str_trim()
  )),
  baker_first_name = str_remove_all(baker_first_name, "\""))  # Removes the quotes from "Jo"

# Import and clean viewers csv

viewers_df <- read_csv("./data/viewers.csv") %>% 
  janitor::clean_names()

# Pivoting viewers_df into long format

viewers_long_df <- viewers_df %>%
  pivot_longer(
    cols = starts_with("series_"),
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
  ) %>%
  mutate(series = as.numeric(series)) %>%
  select(series, everything())

```


## Checking for Incomplete Data between bakers_df and bakes_df

```{r p3_incomplete_data}

# Check for bakers without any competition data

missing_bakers <- bakers_df %>%
  anti_join(bakes_df, by = c("baker_first_name", "series"))
print(missing_bakers)

# Check for bakes information without baker information

missing_bakes <- bakes_df %>%
  anti_join(bakers_df, by = c("baker_first_name", "series"))
print(missing_bakes)

```

There are 25 bakers from bakers_df without bakes information (bakes_df).
There is no bakes data from bakes_df with missing bakers information (bakers_df).

## Merging, cleaning, and exporting final dataset

```{r p3_merging_data}

# Merging bakers_df and bakes_df 

bakers_bake_merged_df <- full_join(bakes_df, bakers_df, 
                                   by = c("baker_first_name", "series"), 
                                   suffix = c("", "_baker")) %>%
    select(baker_first_name, baker_last_name, series, episode, baker_age, baker_occupation, hometown, everything())


# Check for results information missing from bakers_bake_merged_df

missing_results <- results_df %>%
  anti_join(bakers_bake_merged_df, by = c("baker_first_name", "series"))
print(missing_results)

# Correcting baker_first_name discrepancy between datasets

bakers_bake_merged_df <- bakers_bake_merged_df %>%
  mutate(baker_first_name = if_else(baker_first_name == "Jo", "Joanne", baker_first_name))

# Merging bakers_bake_merged_df and results_df 
bakers_bake_merged_df <- bakers_bake_merged_df %>%
  left_join(results_df, by = c("baker_first_name", "series", "episode"))

# Export the merged dataset
write_csv(bakers_bake_merged_df, "./data/gbbo_merged_data.csv")

```
