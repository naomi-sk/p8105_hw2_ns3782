p8105_hw2_ns3782
================
NSK
2024-09-26

# Problem 1

``` r
# Read and clean NYC transit data

nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = case_match(
    entry,
    "YES" ~ TRUE,
    "NO" ~ FALSE,
    .default = NA
  ))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Dataset overview

The cleaned NYC Transit Subway Entrance and Exit dataset contains
information about entrances and exits of subway stations in New York
City. Variables selected for inclusion in the cleaned dataset imported
into R include line, station_name, station_latitude, station_longitude,
route1, route2, route3, route4, route5, route6, route7, route8, route9,
route10, route11, entry, vending, entrance_type, ada.

The data cleaning process involved reading the CSV file from a local
subdirectory /data, cleaning variable names using the janitor package,
selecting variables of interest, and converting the ‘entry’ variable
from character (“YES”/“NO”) to logical (TRUE/FALSE).

The resulting dataset has **1868 rows** and **19 columns**. The dataset
is not tidy because information about routes served is spread across
multiple columns (Route1 through Route11). This does not align with good
tidy data practice, as each variable should form a column and each
observation should form a row.

## How many distinct stations are there?

``` r
nyc_transit_df %>%
  distinct(station_name, line) %>%
  nrow()
```

    ## [1] 465

There are 465 distinct subway stations in the NYC transit subway system.

## How many stations are ADA compliant?

``` r
nyc_transit_df %>%
  filter(ada == TRUE) %>%
  distinct(station_name, line) %>%
  nrow()
```

    ## [1] 84

There are 84 ADA compliant stations.

## What proportion of station entrances / exits without vending allow entrance?

``` r
prop_no_vending_entry <- nyc_transit_df %>%
  filter(vending == "NO") %>%
  summarise(prop = mean(entry, na.rm = TRUE)) %>%
  pull(prop)
```

The proportion of station entrances/exits without vending that allow
entrance is 0.3770492, or 37.7%.

# Problem 2

``` r
# Read and clean Mr. Trash Wheel sheet

mr_trash_wheel_df <- read_excel(
  "./data/trash_wheel_collection_data.xlsx",
  sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N"),
  skip = 1
) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    trash_wheel = "Mr. Trash Wheel",
    year = as.numeric(year)
  )

# Read and clean Professor Trash Wheel sheet

prof_trash_wheel_df <- read_excel(
  "./data/trash_wheel_collection_data.xlsx",
  sheet = "Professor Trash Wheel",
  range = cell_cols("A:M"),
  skip = 1
) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    trash_wheel = "Professor Trash Wheel",
    year = as.numeric(year)
  )

# Read and clean Gwynnda Wheel sheet

gwynnda_trash_wheel_df <- read_excel(
  "./data/trash_wheel_collection_data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = cell_cols("A:L"),
  skip = 1
) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    trash_wheel = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )


# Combine all trash wheel datasets

combined_trash_wheel <- bind_rows(
  mr_trash_wheel_df, 
  prof_trash_wheel_df, 
  gwynnda_trash_wheel_df
) %>%
  select(trash_wheel, everything())



# Total weight collected by Prof Trash Wheel

prof_total_weight <- prof_trash_wheel_df %>%
  summarize(total_weight = sum(weight_tons, na.rm = TRUE)) %>%
  pull(total_weight)

# Total cigarette butts collected by Gwynnda June 2022

gwynnda_june_2022_butts <- gwynnda_trash_wheel_df %>%
  filter(month == "June", year == 2022) %>%
  summarize(total_butts = sum(cigarette_butts, na.rm = TRUE)) %>%
  pull(total_butts)
```

## Combined trash wheel Dataset Overview

The combined Trash Wheel dataset contains 1033 observations and 15
variables. Key variables include the identifier for each trash wheel
(Mr. Trash Wheel, Professor Trash Wheel, Gwynnda Trash Wheel), dumpster,
month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
sports_balls, homes_powered.

The data shows that Professor Trash Wheel has collected a total of
246.74 tons of trash since its deployment. In June 2022, Gwynnda Trash
Wheel collected 18,120 cigarette butts.

# Problem 3

## Importing and Cleaning datasets.

``` r
# Import and clean results csv

results_df <- read_csv("./data/results.csv", skip = 2) %>% 
  janitor::clean_names() %>%
  rename(baker_first_name = baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Import and clean results bakers csv

bakers_df <- read_csv("./data/bakers.csv") %>% 
  janitor::clean_names() %>%
  separate(baker_name, into = c("baker_first_name", "baker_last_name"), sep = " ", extra = "merge")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Import and clean results bakes csv

bakes_df <- read_csv("./data/bakes.csv") %>% 
  janitor::clean_names() %>%
  rename(baker_first_name = baker) %>%
  mutate(across(where(is.character), ~case_match(
    .,
    c("Unknown", "UNKNOWN", "N/A") ~ NA_character_,
    .default = . %>%
      str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
      str_replace_all("(?<=[a-z])with", " with") %>%
      str_replace_all("\\s+", " ") %>%
      str_trim()
  )),
  baker_first_name = str_remove_all(baker_first_name, "\""))  # Removes the quotes from "Jo"
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Import and clean viewers csv

viewers_df <- read_csv("./data/viewers.csv") %>% 
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Pivoting viewers_df into long format

viewers_long_df <- viewers_df %>%
  pivot_longer(
    cols = starts_with("series_"),
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
  ) %>%
  mutate(series = as.numeric(series)) %>%
  select(series, everything())
```

## Checking for Incomplete Data between bakers_df and bakes_df

``` r
# Check for bakers without any competition data

missing_bakers <- bakers_df %>%
  anti_join(bakes_df, by = c("baker_first_name", "series"))
print(missing_bakers)
```

    ## # A tibble: 25 × 6
    ##    baker_first_name baker_last_name series baker_age baker_occupation   hometown
    ##    <chr>            <chr>            <dbl>     <dbl> <chr>              <chr>   
    ##  1 Alice            Fevronia            10        28 Geography teacher  Essex   
    ##  2 Amelia           LeBruin             10        24 Fashion designer   Halifax 
    ##  3 Antony           Amourdoux            9        30 Banker             London  
    ##  4 Briony           Williams             9        33 Full-time parent   Bristol 
    ##  5 Dan              Beasley-Harling      9        36 Full-time parent   London  
    ##  6 Dan              Chambers            10        32 Support worker     Rotherh…
    ##  7 David            Atherton            10        36 International hea… Whitby  
    ##  8 Helena           Garcia              10        40 Online project ma… Leeds   
    ##  9 Henry            Bird                10        20 Student            Durham  
    ## 10 Imelda           McCarron             9        33 Countryside recre… County …
    ## # ℹ 15 more rows

``` r
# Check for bakes information without baker information

missing_bakes <- bakes_df %>%
  anti_join(bakers_df, by = c("baker_first_name", "series"))
print(missing_bakes)
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker_first_name <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

There are 25 bakers from bakers_df without bakes information (bakes_df).
There is no bakes data from bakes_df with missing bakers information
(bakers_df).

## Merging, cleaning, and exporting final dataset

``` r
# Merging bakers_df and bakes_df 

bakers_bake_merged_df <- full_join(bakes_df, bakers_df, 
                                   by = c("baker_first_name", "series")) %>%
    select(baker_first_name, baker_last_name, series, episode, baker_age, baker_occupation, hometown, everything())


# Check for results information missing from bakers_bake_merged_df

missing_results <- results_df %>%
  anti_join(bakers_bake_merged_df, by = c("baker_first_name", "series"))
print(missing_results)
```

    ## # A tibble: 8 × 5
    ##   series episode baker_first_name technical result    
    ##    <dbl>   <dbl> <chr>                <dbl> <chr>     
    ## 1      2       1 Joanne                  11 IN        
    ## 2      2       2 Joanne                  10 IN        
    ## 3      2       3 Joanne                   1 IN        
    ## 4      2       4 Joanne                   8 IN        
    ## 5      2       5 Joanne                   6 IN        
    ## 6      2       6 Joanne                   1 STAR BAKER
    ## 7      2       7 Joanne                   3 IN        
    ## 8      2       8 Joanne                   1 WINNER

``` r
# Correcting baker_first_name discrepancy between datasets

bakers_bake_merged_df <- bakers_bake_merged_df %>%
  mutate(baker_first_name = if_else(baker_first_name == "Jo", "Joanne", baker_first_name))

# Merging bakers_bake_merged_df and results_df 

bakers_bake_merged_df <- bakers_bake_merged_df %>%
  full_join(results_df, by = c("baker_first_name", "series", "episode")) 

# Remove rows where contestants did not participate (ie where there were no results)

bakers_bake_merged_df <- bakers_bake_merged_df %>%
  filter(!is.na(result))

# Export the merged dataset

write_csv(bakers_bake_merged_df, "./data/gbbo_merged_data.csv")

# Identify potential duplicates

duplicates <- bakers_bake_merged_df %>%
  group_by(series, episode, baker_first_name) %>%
  filter(n() > 1) %>%
  arrange(series, episode, baker_first_name)
```

## Data Cleaning Process

The first step in my data wrangling process involved importing and
cleaning all 4 datasets. I used the janitor package to convert column
names into snake case. For the results.csv, the first two rows were
skipped to avoid a header in the data. For some datasets, data cleaning
and wrangling required extra steps. For instance, with bakers.csv, I
decided to split the baker names into first and last names. This ensured
that variables across multiple datasets were consistent and
appropriately defined in preparation for merging datasets later on. In
the case of bakes.csv, I also had some minor formatting to do to address
trailing whitespace, incorrect punctuation in string characters, and
ensuring correct spacing between words. Viewers.csv was not in tidy
format. As a result, I had to pivot it into long format for it to be
tidy, with each variable forming a column and each observation forming a
row.

As part of my data cleaning process, I checked for inconsistent/missing
data across datasets. Anti-joins were used to check for bakers without
competition data and bakes without baker information. From this, I found
that there were 25 bakers from bakers_df without bakes information
(bakes_df). There was no bakes data from bakes_df with missing bakers
information (bakers_df).

While I had the opportunity to remove the 25 bakers from the dataset, I
chose not to so as to preserve as much information as possible. These
bakers might represent contestants who were selected but didn’t
participate in any bakes, or there might be missing data for their
bakes. Keeping this information could be valuable for future analyses or
for understanding the completeness of the dataset.

Questions I had were:

- Why are there 25 bakers without bakes information? Are these from
  specific seasons or years?
- Should I include these bakers in the final merged dataset, even though
  they lack bake information?
- How should I handle potential discrepancies in baker names across
  datasets?

After careful consideration, I decided to keep all bakers in the dataset
and use a full join when merging bakers_df and bakes_df to ensure no
information was lost. First, I used full_join on baker_first_name and
series to merge bakes_df and bakers_df in order to preserve all
information across both datasets. As expected based on the check I did
previously, this dataset bakers_bake_merged_df had 25 observations
(bakers) without bakes information.

Next, I checked for inconsistent/missing data across datasets between
the merged dataset and results_df. There were 8 observations (bakers) in
the results_df that did not appear in the merged dataset. However, upon
observation, this issue was a name discrepancy. In results_df, the baker
was named “Joanne”, however in bakers_bake_merged_df, the same baker is
named “Jo”. I confirmed that these were the same individual by looking
up contestant information details of the Great British Bakeoff season 2
online.

In order to rectify this discrepancy, I renamed “Jo” from
bakers_bake_merged_df to “Joanne” to be consistent across datasets. I
then merged results_df with bakers_bake_merged_df to create the final
Great British Bakeoff dataset. After merging, I performed a check for
duplicates, looking at whether a baker might have multiple entries for
the same episode and series. I also removed rows where contestants did
not participate in the episode/series. I also checked whether the merged
dataset contained all the necessary variables from each of the original
datasets.

I then exported this data as a CSV in the appropriate local directory.

## Great British Bakeoff: Final dataset description

The final merged GBBO dataset provides a comprehensive view of the
competition across multiple seasons. The dataset contains 710 rows and
11 columns. It includes data for 107 unique contestants across 10
seasons of the show. It provides additional information about each
contestant, including their age, occupation and hometown, their baking,
and their performance throughout the competition. The ages of
contestants range from 17 to 71 years old, with an average age of 36.9
years.

## Season Star Bakers and Overview

``` r
star_bakers <- bakers_bake_merged_df %>%
  filter(series >= 5 & series <= 10, 
         result %in% c("STAR BAKER", "WINNER")) %>%
  select(series, episode, baker_first_name, result) %>%
  arrange(series, episode)

# Create readable table

knitr::kable(star_bakers, 
             caption = "Star Bakers and Winners (Seasons 5-10)",
             col.names = c("Season", "Episode", "Baker", "Result"))
```

| Season | Episode | Baker     | Result     |
|-------:|--------:|:----------|:-----------|
|      5 |       1 | Nancy     | STAR BAKER |
|      5 |       2 | Richard   | STAR BAKER |
|      5 |       3 | Luis      | STAR BAKER |
|      5 |       4 | Richard   | STAR BAKER |
|      5 |       5 | Kate      | STAR BAKER |
|      5 |       6 | Chetna    | STAR BAKER |
|      5 |       7 | Richard   | STAR BAKER |
|      5 |       8 | Richard   | STAR BAKER |
|      5 |       9 | Richard   | STAR BAKER |
|      5 |      10 | Nancy     | WINNER     |
|      6 |       1 | Marie     | STAR BAKER |
|      6 |       2 | Ian       | STAR BAKER |
|      6 |       3 | Ian       | STAR BAKER |
|      6 |       4 | Ian       | STAR BAKER |
|      6 |       5 | Nadiya    | STAR BAKER |
|      6 |       6 | Mat       | STAR BAKER |
|      6 |       7 | Tamal     | STAR BAKER |
|      6 |       8 | Nadiya    | STAR BAKER |
|      6 |       9 | Nadiya    | STAR BAKER |
|      6 |      10 | Nadiya    | WINNER     |
|      7 |       1 | Jane      | STAR BAKER |
|      7 |       2 | Candice   | STAR BAKER |
|      7 |       3 | Tom       | STAR BAKER |
|      7 |       4 | Benjamina | STAR BAKER |
|      7 |       5 | Candice   | STAR BAKER |
|      7 |       6 | Tom       | STAR BAKER |
|      7 |       7 | Andrew    | STAR BAKER |
|      7 |       8 | Candice   | STAR BAKER |
|      7 |       9 | Andrew    | STAR BAKER |
|      7 |      10 | Candice   | WINNER     |
|      8 |       1 | Steven    | STAR BAKER |
|      8 |       2 | Steven    | STAR BAKER |
|      8 |       3 | Julia     | STAR BAKER |
|      8 |       4 | Kate      | STAR BAKER |
|      8 |       5 | Sophie    | STAR BAKER |
|      8 |       6 | Liam      | STAR BAKER |
|      8 |       7 | Steven    | STAR BAKER |
|      8 |       8 | Stacey    | STAR BAKER |
|      8 |       9 | Sophie    | STAR BAKER |
|      8 |      10 | Sophie    | WINNER     |
|      9 |       1 | Manon     | STAR BAKER |
|      9 |       2 | Rahul     | STAR BAKER |
|      9 |       3 | Rahul     | STAR BAKER |
|      9 |       4 | Dan       | STAR BAKER |
|      9 |       5 | Kim-Joy   | STAR BAKER |
|      9 |       6 | Briony    | STAR BAKER |
|      9 |       7 | Kim-Joy   | STAR BAKER |
|      9 |       8 | Ruby      | STAR BAKER |
|      9 |       9 | Ruby      | STAR BAKER |
|      9 |      10 | Rahul     | WINNER     |
|     10 |       1 | Michelle  | STAR BAKER |
|     10 |       2 | Alice     | STAR BAKER |
|     10 |       3 | Michael   | STAR BAKER |
|     10 |       4 | Steph     | STAR BAKER |
|     10 |       5 | Steph     | STAR BAKER |
|     10 |       6 | Steph     | STAR BAKER |
|     10 |       7 | Henry     | STAR BAKER |
|     10 |       8 | Steph     | STAR BAKER |
|     10 |       9 | Alice     | STAR BAKER |
|     10 |      10 | David     | WINNER     |

Star Bakers and Winners (Seasons 5-10)

In season 5, Nancy was the dark horse of the competition - she only
received the Star Baker award once in the first episode, but won the
entire episode at the end of the season. In season 6, it seemed a bit
more predictable towards the later half of the series. While Ian seemed
strong for the first few episodes, winning 3 Star Baker awards until
episode 4, Nadiya began to outperform him in later episodes - garnering
3 Star Baker awards in the latter part of the series, and winning the
competition overall. Season 7 seemed harder to predict a clear winner
early on, however Candice won the most Star Baker awards before winning
the whole competition. In Season 8, Steven did consistently well,
earning two Star Baker awards early on in the season and three overall.
However, Sophie secured the win unexpectedly later on in the season,
even though she only won two Star Baker awards overall.

## Viewers Data

``` r
# Show the first 10 rows of tidy viewers data

head(viewers_long_df, 10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewers
    ##     <dbl>   <dbl>   <dbl>
    ##  1      1       1    2.24
    ##  2      2       1    3.1 
    ##  3      3       1    3.85
    ##  4      4       1    6.6 
    ##  5      5       1    8.51
    ##  6      6       1   11.6 
    ##  7      7       1   13.6 
    ##  8      8       1    9.46
    ##  9      9       1    9.55
    ## 10     10       1    9.62

``` r
# Average viewership Season 1

mean_viewer_s1 <- viewers_long_df %>%
  filter(series == 1) %>%
  summarise(average_viewership = mean(viewers, na.rm = TRUE))

# Average viewership Season 5

mean_viewer_s5 <- viewers_long_df %>%
  filter(series == 5) %>%
  summarise(average_viewership = mean(viewers, na.rm = TRUE))
```

The average viewership in season 1 was 2.77 units unspecified,
increasing to an average viewership of 10.0393 units unspecified in
season 5.
